---
version: "3"

services:

  ecowitt2mqtt:
    container_name: ecowitt2mqtt
    depends_on:
      - vernemq
    environment:
      HASS_DISCOVERY: "true"
      MQTT_BROKER: vernemq
      MQTT_PASSWORD: "${VERNEMQ_PASSWORD_ECOWITT}"
      MQTT_USERNAME: ecowitt
    image: "bachya/ecowitt2mqtt:${ECOWITT2MQTT_VERSION}"
    ports:
      - "8080:8080/tcp"
    restart: always

  esphome:
    container_name: esphome
    depends_on:
      - traefik
    image: "esphome/esphome:${ESPHOME_VERSION}"
    network_mode: host
    restart: always
    volumes:
      - ./esphome:/config

  fail2ban:
    cap_add:
      - NET_ADMIN
      - NET_RAW
    container_name: fail2ban
    environment:
      F2B_DB_PURGE_AGE: 1d
      F2B_MAX_RETRY: 3
      TZ: America/Denver
    image: "crazymax/fail2ban:${FAIL2BAN_CONTAINER_VERSION}"
    network_mode: "host"
    restart: always
    volumes:
      - ./fail2ban/settings/filter.d:/data/filter.d:ro
      - ./fail2ban/settings/jail.d:/data/jail.d:ro
      - ./fail2ban/settings/jail.local:/data/jail.local:ro
      - /var/log:/var/log:ro
      - fail2ban-data:/data

  glances:
    container_name: glances
    environment:
      GLANCES_OPT: "-w"
    image: "nicolargo/glances:dev"
    network_mode: "host"
    restart: always

  hass:
    container_name: hass
    depends_on:
      - hass-db
      - traefik
      - vernemq
      - zwave-js
    image: "homeassistant/home-assistant:${HOME_ASSISTANT_CORE_VERSION}"
    labels:
      traefik.enable: true
      traefik.http.routers.hass.middlewares: security
      traefik.http.routers.hass.entrypoints: websecure
      traefik.http.routers.hass.rule: "Host(`${TRAEFIK_HOST_HASS}`)"
      traefik.http.routers.hass.tls: true
      traefik.http.services.hass.loadbalancer.server.port: 8123
    network_mode: host
    restart: always
    volumes:
      - ./hass/settings/blueprints:/config/blueprints
      - ./hass/settings/conf:/config/conf
      - ./hass/settings/configuration.yaml:/config/configuration.yaml
      - ./hass/settings/custom_components:/config/custom_components
      - ./hass/settings/scenes.yaml:/config/scenes.yaml
      - ./hass/settings/secrets.yaml:/config/secrets.yaml
      - ./hass/settings/ssh_keys:/config/ssh_keys
      - hass-config:/config

  hass-db:
    container_name: hass-db
    environment:
      POSTGRES_DB: "${HASS_DB_NAME}"
      POSTGRES_PASSWORD: "${HASS_DB_PASSWORD}"
      POSTGRES_USER: "${HASS_DB_USER}"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${HASS_DB_USER}"]
      interval: 5s
      timeout: 10s
      retries: 3
    image: "postgres:${POSTGRES_VERSION}-alpine"
    ports:
      - "5432:5432/tcp"
    restart: always
    volumes:
      - hass-db-data:/var/lib/postgresql/data

  restic-backup:
    container_name: restic-backup
    environment:
      B2_ACCOUNT_ID: "${RESTIC_B2_ACCOUNT_ID}"
      B2_ACCOUNT_KEY: "${RESTIC_B2_ACCOUNT_KEY}"
      BACKUP_CRON: "15 * * * *"
      POST_COMMANDS_SUCCESS: "curl -s ${HEALTHCHECKS_BACKUP_URL}"
      RESTIC_BACKUP_ARGS: >-
        --exclude=".cache"
        --verbose
      RESTIC_BACKUP_SOURCES: /data
      RESTIC_FORGET_ARGS: >-
        --keep-last 10
        --keep-daily 7
        --keep-weekly 2
        --keep-monthly 1
      RESTIC_PASSWORD: "${RESTIC_PASSWORD}"
      RESTIC_REPOSITORY: "${RESTIC_REPOSITORY}"
      RUN_ON_STARTUP: "true"
      TZ: America/Denver
    image: mazzolino/restic:latest
    restart: always
    volumes:
      - /etc:/data/etc:ro
      - /home:/data/home:ro
      - /root:/data/root:ro
      - /usr/local:/data/usr/local:ro
      - /var/lib/docker/volumes:/data/var/lib/docker/volumes:ro

  restic-prune:
    container_name: restic-prune
    environment:
      B2_ACCOUNT_ID: "${RESTIC_B2_ACCOUNT_ID}"
      B2_ACCOUNT_KEY: "${RESTIC_B2_ACCOUNT_KEY}"
      PRUNE_CRON: "0 0 4 * * *"
      RESTIC_PASSWORD: "${RESTIC_PASSWORD}"
      RESTIC_REPOSITORY: "${RESTIC_REPOSITORY}"
      RUN_ON_STARTUP: "true"
      TZ: America/Denver
    image: mazzolino/restic:latest
    restart: always

  scrutiny:
    cap_add:
      - SYS_RAWIO
    container_name: scrutiny
    devices:
      - /dev/sda
    image: "analogj/scrutiny:v${SCRUTINY_VERSION}-omnibus"
    ports:
      - "8081:8080"
    volumes:
      - ./scrutiny/settings/collector.yaml:/scrutiny/config/collector.yaml:ro
      - ./scrutiny/settings/scrutiny.yaml:/scrutiny/config/scrutiny.yaml:ro
      - /run/udev:/run/udev:ro
      - scrutiny-config:/scrutiny/config

  traefik:
    command:
      - "--accesslog.filepath=/var/log/access.log"
      - "--accesslog.filters.statusCodes=400-499"
      - "--api"
      - "--certificatesResolvers.linode.acme.dnschallenge.resolvers=1.1.1.1:53,1.0.0.1:53"
      - "--certificatesresolvers.linode.acme.dnschallenge.provider=linodev4"
      - "--certificatesresolvers.linode.acme.dnschallenge=true"
      - "--certificatesresolvers.linode.acme.email=${ACME_EMAIL_ADDRESS}"
      - "--certificatesresolvers.linode.acme.storage=/letsencrypt/acme.json"
      - "--entrypoints.websecure.address=:443"
      - "--providers.docker"
      - "--providers.docker.exposedbydefault=false"
      - "--providers.file.directory=/etc/traefik/"
    container_name: traefik
    environment:
      LINODE_PROPAGATION_TIMEOUT: 900
      LINODE_TOKEN: "${TRAEFIK_LINODE_API_KEY}"
    extra_hosts:
      - "host.docker.internal:172.17.0.1"
    image: "traefik:${TRAEFIK_VERSION}"
    labels:
      # Middlewares:
      traefik.http.middlewares.auth.basicauth.users: "${TRAEFIK_USERS}"
      traefik.http.middlewares.security.ratelimit.average: 100
      traefik.http.middlewares.security.ratelimit.burst: 50

      # Global Wildcard Certs:
      traefik.http.routers.wildcard-certs.tls.certresolver: linode
      traefik.http.routers.wildcard-certs.tls.domains[0].main: >
        ${TRAEFIK_DOMAIN}
      traefik.http.routers.wildcard-certs.tls.domains[0].sans: >
        *.${TRAEFIK_DOMAIN}

      # Dashboard:
      traefik.enable: true
      traefik.http.routers.traefik.entrypoints: websecure
      traefik.http.routers.traefik.middlewares: auth,security
      traefik.http.routers.traefik.rule: "Host(`${TRAEFIK_HOST_TRAEFIK}`)"
      traefik.http.routers.traefik.service: api@internal
      traefik.http.routers.traefik.tls.certresolver: linode
    ports:
      - "443:443/tcp"
    restart: always
    volumes:
      - ./traefik/settings:/etc/traefik:ro
      - /var/log/traefik:/var/log
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - letsencrypt-data:/letsencrypt

  vernemq:
    container_name: vernemq
    environment:
      DOCKER_VERNEMQ_ACCEPT_EULA: "yes"
      DOCKER_VERNEMQ_USER_ECOWITT: "${VERNEMQ_PASSWORD_ECOWITT}"
      DOCKER_VERNEMQ_USER_HASS: "${VERNEMQ_PASSWORD_HASS}"
      DOCKER_VERNEMQ_USER_WYZE: "${VERNEMQ_PASSWORD_WYZE}"
      DOCKER_VERNEMQ_PLUGINS.vmq_bridge: "on"
      DOCKER_VERNEMQ_vmq_bridge.ssl.br0.cafile: >
        /etc/ssl/certs/DST_Root_CA_X3.pem
      DOCKER_VERNEMQ_vmq_bridge.ssl.br0.insecure: "on"
      DOCKER_VERNEMQ_vmq_bridge.ssl.br0.max_outgoing_buffered_messages: 100
      DOCKER_VERNEMQ_vmq_bridge.ssl.br0.password: "${VERNEMQ_BRIDGE_PASSWORD}"
      DOCKER_VERNEMQ_vmq_bridge.ssl.br0.topic.1: "* in"
      DOCKER_VERNEMQ_vmq_bridge.ssl.br0.username: hub_mqtt
      DOCKER_VERNEMQ_vmq_bridge.ssl.br0: "${VERNEMQ_BRIDGE_HOST}"
    healthcheck:
      test: ["CMD-SHELL", "vernemq ping | grep -q pong"]
      interval: 5s
      timeout: 10s
      retries: 3
    image: "vernemq/vernemq:${VERNEMQ_VERSION}-alpine"
    ports:
      - "1883:1883/tcp"
    restart: always
    user: root
    volumes:
      - /etc/ssl:/etc/ssl:ro
      - /usr/share/ca-certificates:/usr/share/ca-certificates:ro
      - vernemq-data:/vernemq/data

  zwave-js:
    container_name: zwave-js
    devices:
      - "/dev/zwave:/dev/zwave"
    environment:
      NETWORK_KEY: "${ZWAVE_NETWORK_KEY}"
    image: "zwavejs/zwavejs2mqtt:${ZJS2M_VERSION}"
    ports:
      - "3000:3000/tcp"
      - "8091:8091/tcp"
    restart: always
    volumes:
      - zwave-js-config:/usr/src/app/store

volumes:

  fail2ban-data:
  hass-config:
  hass-db-data:
  letsencrypt-data:
  scrutiny-config:
  vernemq-data:
  zwave-js-config:
